import h5py
import cv2
import numpy as np
import sys, os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))), "UnionCut"))
from DINOinference import TokenGraphCut
from multiprocessing import Pool, Manager, Process
import argparse


def h5writer(result_queue, patch_size=16, resize_mode="flexible", UnionCut_patch_size=8, UnionCut_resize_mode="fixed"):
    # create the h5 file
    file = h5py.File("./h5/TokenUnionCutN1_tao0.2_COCO20K_Trainval_ViT_S_" + str(patch_size) + "_" + resize_mode + "_" + str(UnionCut_patch_size) + "_" + UnionCut_resize_mode +".h5", "w")
    # create a group to save pseudo-labels generated by the current method
    method_group = file.create_group("TokenGraphCut")
    print("SAVER is ready")
    # save results one by one
    while True:
        result = result_queue.get()
        if result == "end":
            # finish when the mask generation is finished
            break
        try:
            # obtain info of the image
            image, image_name, local_path, image_path, masks, fore_union = result
            # save path of the image
            method_group.create_dataset(image_name + '/path', data=image_path)
            # save the mask
            method_group.create_dataset(image_name + '/masks', data=masks, compression="gzip", compression_opts=9)
            # save the foreground union
            method_group.create_dataset(image_name + '/union', data=fore_union, compression="gzip", compression_opts=9)
        except:
            print("error")
            continue
    # close the h5 file
    file.close()


def mask_generation(result_queue, image_name, local_path, image_path, UnionCut_patch_size, UnionCut_resize_mode):
    #try:
    # load the image
    image = cv2.imread(local_path)
    # obtain masks
    masks, fore_union = TokenGraphCut(image, patch_size=UnionCut_patch_size, resize_mode=UnionCut_resize_mode)
    # filter masks with 0 area
    areas = []
    for i in range(masks.shape[0]):
        mask = cv2.resize(masks[i], (fore_union.shape[1], fore_union.shape[0]), cv2.INTER_NEAREST)
        areas.append(np.sum(mask))
    areas = np.array(areas)
    if np.sum(areas) == 0:
        return
    masks = masks[areas > 0, :, :]
    # send the result to saver
    result_queue.put((image, image_name, local_path, image_path, masks, fore_union))
    #except:
    #print("generation no")
    #return


if __name__ == "__main__":
    parser = argparse.ArgumentParser('Saving TokenCut+UnionCut results to h5')
    # default arguments
    parser.add_argument('--dataset', type=str, default="/home/wzl/DataSet/", help='root path of the COCO20K dataset')
    parser.add_argument('--process-num', type=int, default=28,
                        help='the number of subprocesses launched for acceleration')
    args = parser.parse_args()

    # obtain paths of each image
    root_path = args.dataset
    patch_size = 16
    resize_mode = "flexible"
    UnionCut_patch_size = 8
    UnionCut_resize_mode = "fixed"

    fh = open(root_path + "coco/coco_20k_filenames.txt",
              'r')
    # save names of each image
    image_names = [line.strip('\n').split('/')[1].split('.')[0] for line in fh]
    fh.close()

    # save absolute paths of each image in the computer
    local_paths = [root_path + "coco/train2014/" + image_name + ".jpg"
                   for image_name in image_names]
    # save relevant paths of each image under the dataset
    image_paths = ["coco/train2014/" + image_name + ".jpg" for image_name in image_names]

    manager = Manager()
    result_queue = manager.Queue()

    # create and launch h5writer
    h5writer_process = Process(target=h5writer, args=(result_queue, patch_size, resize_mode, UnionCut_patch_size, UnionCut_resize_mode,))
    h5writer_process.start()

    # traverse images
    counter = 0
    # initialize process pool
    processes = []
    # initialize process pool size
    process_num = args.process_num
    while True:
        # remove subprocesses which have finished
        for process in processes[:]:
            if not process.is_alive():
                processes.remove(process)
        # start new sub-process to simulate games
        if len(processes) < process_num and counter < len(image_names):
            for _ in range(process_num - len(processes)):
                # obtain current image
                image_name, local_path, image_path = image_names[counter], local_paths[counter], image_paths[counter]
                # create a new sub-process
                p = Process(target=mask_generation, args=(result_queue, image_name, local_path, image_path, UnionCut_patch_size, UnionCut_resize_mode,))
                p.start()
                processes.append(p)
                counter += 1
                print(counter)
                if counter == len(image_names):
                    break
        # finish
        if len(processes) == 0 and counter == len(image_names):
            break

    # end h5 writer
    result_queue.put("end")
    h5writer_process.join()
    print("done")
